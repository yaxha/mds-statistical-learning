{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio Forward Propagation\n",
    "**José Barrios - 20007192**\n",
    "\n",
    "## Instrucciones\n",
    "Implementar forward-propagation para los 3 diagramas dados, en el tercer diagrama analizar la representación intermedia (ver descripción detallada en diapositiva 8).\n",
    "\n",
    "## Definición de función de propagación \n",
    "Contrsuiremos una función que reciba las matrices de pesos entre capas. Para esto se necesita tener una estructura de datos (lista) que tenga en memoria todas estas matrices de pesos sinápticos.\n",
    "\n",
    "Cada una de las matrices de pesos necesita estar construida de tal manera que la cantidad de filas represente la cantidad de variables de una obseración X (las columnas de X), y que la cantidad de columnas de la matriz sea la cantidad de neuronas de la siguiente capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de activación \n",
    "def sigmoid(X):\n",
    "  return 1/(1 + np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedNeuronal:\n",
    "  def __init__(self, W):\n",
    "    self.W = W\n",
    "\n",
    "  def forward_propagation(self, X):\n",
    "    #X como entrada de la primera capa oculta\n",
    "    #A será representará la entrada de las siguientes capas y luego la salida final\n",
    "    A = X\n",
    "    \n",
    "    #Ciclo para calcular los valores de cada capa\n",
    "    for pesos in self.W:\n",
    "        z = np.matmul(A, pesos)\n",
    "        A = sigmoid(z)\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagrama 1\n",
    "\n",
    "<img src='diagrama1.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pesos de las entradas hacia la capa oculta 1\n",
    "W_I_H1 = np.array([[0.8, 0.4, 0.3],\n",
    "                   [0.2, 0.9, 0.5]])\n",
    "\n",
    "#Pesos de la capa oculta 1 hacia la salida\n",
    "W_H1_O = np.array([[0.3], \n",
    "                   [0.5], \n",
    "                   [0.9]])\n",
    "\n",
    "#Lista de pesos entre capas\n",
    "W = [W_I_H1, W_H1_O]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_diagrama1 = np.array([1, 1]) #Para determinar que sea la misma salida de la imagen (0.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_diagrama1 = RedNeuronal(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77438027])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_diagrama1.forward_propagation(input_diagrama1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la misma salida de la imagen, así que podemos probar con entradas con mayor cantidad de observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_diagrama1 = np.array([[1, 1], \n",
    "                           [0, 0], \n",
    "                           [0, 1], \n",
    "                           [1, 0], \n",
    "                           [0.5, 0.5], \n",
    "                           [0.75, 0.25], \n",
    "                            [0.1, 0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77438027],\n",
       "       [0.70056714],\n",
       "       [0.74661477],\n",
       "       [0.7356216 ],\n",
       "       [0.74155414],\n",
       "       [0.73869891],\n",
       "       [0.71414222]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_diagrama1.forward_propagation(input_diagrama1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagrama 2\n",
    "\n",
    "<img src='diagrama2.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pesos de las entradas hacia la capa oculta 1\n",
    "W_I_H1 = np.array([[0.9, 0.3, 0.2],\n",
    "                   [0.8, 0.5, 0.4], \n",
    "                   [0.1, 0.6, 0.7]])\n",
    "\n",
    "#Pesos de la capa oculta 1 hacia la salida\n",
    "W_H1_O = np.array([[0.3], \n",
    "                   [0.5], \n",
    "                   [0.9]])\n",
    "\n",
    "#Lista de pesos entre capas\n",
    "W = [W_I_H1, W_H1_O]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_diagrama2 = np.array([1, 0, 1]) #Para determinar que sea la misma salida de la imagen (0.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_diagrama2 = RedNeuronal(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77112013])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_diagrama2.forward_propagation(input_diagrama2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_diagrama2 = np.array([[0.5, 0.5, 0.5], \n",
    "                            [0.2, 1, 0], \n",
    "                            [-1, 0, 1], \n",
    "                            [-0.2, -0.5, 0], \n",
    "                            [0.1, 0.2, 0.5], \n",
    "                            [0.4, 0.2, 0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7574387 ],\n",
       "       [0.74721089],\n",
       "       [0.71918899],\n",
       "       [0.67161418],\n",
       "       [0.73591525],\n",
       "       [0.72614304]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_diagrama2.forward_propagation(input_diagrama2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagrama 3\n",
    "\n",
    "<img src='diagrama3.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pesos de las entradas hacia la capa oculta 1\n",
    "W_I_H1 = np.array([[0.3, 0.22, 0.65],\n",
    "                   [0.46, -0.7, 0.9], \n",
    "                   [0.02, 0.65, 0.34]])\n",
    "\n",
    "#Pesos de la capa oculta 1 hacia la capa oculta 2\n",
    "W_H1_H2 = np.array([[-0.3, 0.45, 0.65],\n",
    "                   [0.62, 0.57, 0.58], \n",
    "                   [0.45, 0.48, -0.45]])\n",
    "\n",
    "#Pesos de la capa oculta 1 hacia la salida\n",
    "W_H2_O = np.array([[-0.23, 0.9], \n",
    "                   [0.22, 0.88], \n",
    "                   [0.77, -0.4]])\n",
    "\n",
    "#Lista de pesos entre capas\n",
    "W = [W_I_H1, W_H1_H2, W_H2_O]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_diagrama3 = RedNeuronal(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61889026, 0.7270697 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_diagrama3 = np.array([1, 0, 1])\n",
    "red_diagrama3.forward_propagation(input_diagrama3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61605707, 0.72085441],\n",
       "       [0.6191183 , 0.70940566],\n",
       "       [0.618896  , 0.72913813],\n",
       "       [0.61939623, 0.73501733],\n",
       "       [0.62203047, 0.73593835],\n",
       "       [0.61566286, 0.71211039]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_diagrama3 = np.array([[0, 0.5, 1], \n",
    "                           [-1, -0.5, 1], \n",
    "                           [0.1, 0.3, 2], \n",
    "                           [0, 1, 3], \n",
    "                           [3, 0, 1], \n",
    "                           [0.1, 0.1, 0.1]])\n",
    "red_diagrama3.forward_propagation(input_diagrama3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "Es necesario tener presente la dimensionaldiad de las matrices para que no surjan errores de dimensionalidad no compatible. Realizar primero las operaciones a mano es un buen ejercicio para captar la idea de forward propagation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
