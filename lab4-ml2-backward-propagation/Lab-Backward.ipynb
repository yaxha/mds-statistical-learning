{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Laboratorio: Backward Propagation**\n",
    "**José Barrios - 20007192**\n",
    "\n",
    "## Instrucciones\n",
    "Usar Numpy para entrenar un aproximador para la función XOR usando dos capas intermedias. Se solicita:\n",
    "* Usar dos neuronas o más en la primera capa oculta\n",
    "* Usar exactamente dos neuronas en la segunda capa oculta (capa previa a la salida)\n",
    "* Usar activación ReLu\n",
    "\n",
    "Además, se solicita realizar al menos 5 experimentos. Para cada experimento:\n",
    "* Inicializar los parámetros aleatoriamente con distribución normal centrada en 0 y desviación estándar de 0.1\n",
    "* Retornar la representación intermedia de la segunda capa oculta\n",
    "\n",
    "Por último, graficar las 5 representaciones intermedias, comprarar y concluir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de funcionalidad\n",
    "Varias pruebas de funcionalidades que serán útiles para definir la clase y métodos de la red neuronal. Todo esto es omitible y se puede salrar a la sección de RedNeuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir funciones de activación y su derivada\n",
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return x > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_deriv(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10319707, -0.1274431 , -0.05905622],\n",
       "       [-0.03669341, -0.05381003, -0.0623852 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inicialización con distribución normal\n",
    "np.random.normal(loc=0, scale=0.1, size=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tablas de verdad de XOR\n",
    "tablaXor = np.array([[0, 0], \n",
    "                     [0, 1], \n",
    "                     [1, 0], \n",
    "                     [1, 1]])\n",
    "labelXor = np.array([[0, 1, 1, 0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelXor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "W_I_H1 = np.random.normal(loc=0, scale=0.1, size=(2, 3)) #Capa oculta de 3 neuronas\n",
    "W_H1_H2 = np.random.normal(loc=0, scale=0.1, size=(3, 2)) #Capa oculta de 2 neuronas\n",
    "W_H2_O = np.random.normal(loc=0, scale=0.1, size=(2, 1)) #Pesos hacia la capa de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10856306  0.09973454  0.02829785]\n",
      " [-0.15062947 -0.05786003  0.16514365]]\n",
      "[[-0.24266792 -0.04289126]\n",
      " [ 0.12659363 -0.08667404]\n",
      " [-0.06788862 -0.0094709 ]]\n",
      "[[ 0.14913896]\n",
      " [-0.0638902 ]]\n"
     ]
    }
   ],
   "source": [
    "print(W_I_H1)\n",
    "print(W_H1_H2)\n",
    "print(W_H2_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = [W_I_H1, W_H1_H2, W_H2_O]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.        ]\n",
      " [-0.15062947 -0.05786003  0.16514365]\n",
      " [-0.10856306  0.11328885  0.02121298]\n",
      " [-0.25919253  0.05542883  0.18635663]]\n",
      "[[ 0.          0.        ]\n",
      " [-0.0107193  -0.00156406]\n",
      " [ 0.01415447 -0.01002011]\n",
      " [-0.00449717 -0.0065692 ]]\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.00221688]\n",
      " [0.        ]]\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.00221688]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Forward propagation (una iteración)\n",
    "\n",
    "A = tablaXor #Entrada original\n",
    "Capa = [] #Almacenamiento de resultados intermedios\n",
    "Capa.append(A) #Capa 0 = input\n",
    "    \n",
    "#Ciclo para calcular los valores de cada capa\n",
    "#Recorre desde la capa de entrada hasta la de salida\n",
    "for pesos in W:\n",
    "    z = np.matmul(A, pesos) #Preactivación \n",
    "    A = relu(z) #Activación \n",
    "    Capa.append(A)\n",
    "    print(z)\n",
    "\n",
    "#Predicción \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [1.        ],\n",
       "       [0.99680959],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Error de la predicción\n",
    "error = (A - labelXor)**2\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [-1.        ]\n",
      " [-0.99778312]\n",
      " [ 0.        ]]\n",
      "[[ 0.          0.        ]\n",
      " [-0.          0.        ]\n",
      " [-0.15627305  0.        ]\n",
      " [ 0.          0.        ]]\n",
      "[[ 0.        ]\n",
      " [-1.        ]\n",
      " [-0.99778312]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Backward propagation (una iteración)\n",
    "lr = 0.5\n",
    "\n",
    "layer3_delta = Capa[-1] - labelXor #Error entre predicción y salida real\n",
    "print(layer3_delta)\n",
    "\n",
    "layer2_delta = np.matmul(layer3_delta, W[-1].T) * relu_deriv(Capa[-2])\n",
    "print(layer2_delta)\n",
    "\n",
    "layer1_delta = np.matmul(layer2_delta, W[-2].T) * relu_deriv(Capa[-3])\n",
    "print(layer3_delta)\n",
    "\n",
    "#Actualización de pesos\n",
    "W[-1] -= lr * np.matmul(Capa[-2].T, layer3_delta)\n",
    "W[-2] -= lr * np.matmul(Capa[-3].T, layer2_delta)\n",
    "W[-3] -= lr * np.matmul(Capa[-4].T, layer1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicialización de pesos\n",
    "np.random.seed(1)\n",
    "W_I_H1 = np.random.normal(loc=0, scale=0.1, size=(2, 3)) #Capa oculta de 3 neuronas\n",
    "W_H1_H2 = np.random.normal(loc=0, scale=0.1, size=(3, 2)) #Capa oculta de 2 neuronas\n",
    "W_H2_O = np.random.normal(loc=0, scale=0.1, size=(2, 1)) #Pesos hacia la capa de salida\n",
    "\n",
    "W = [W_I_H1, W_H1_H2, W_H2_O]\n",
    "#print(W)\n",
    "\n",
    "#Ciclo de iteraciones \n",
    "for epoch in range(0, 60):\n",
    "    #Forward propagation\n",
    "    A = tablaXor #Entrada original\n",
    "    Capa = [] #Almacenamiento de resultados intermedios\n",
    "    Capa.append(A) #Capa 0 = input \n",
    "\n",
    "    #Ciclo para calcular los valores de cada capa\n",
    "    #Recorre desde la capa de entrada hasta la de salida\n",
    "    for pesos in W:\n",
    "        z = np.matmul(A, pesos) #Preactivación \n",
    "        A = relu(z) #Activación \n",
    "        Capa.append(A)\n",
    "        \n",
    "    #Backward propagation\n",
    "    lr = 0.5\n",
    "    error = (0.5*(Capa[-1] - labelXor)**2).mean()\n",
    "    \n",
    "    #layer3_delta = Capa[-1] - labelXor #Error entre predicción y salida real\n",
    "    #layer2_delta = np.matmul(layer3_delta, W_H2_O.T) * relu_deriv(Capa[-2])\n",
    "    #layer1_delta = np.matmul(layer2_delta, W_H1_H2.T) * relu_deriv(Capa[-3])\n",
    "\n",
    "    #Actualización de pesos\n",
    "    #W_H2_O -= lr * np.matmul(Capa[-2].T, layer3_delta)\n",
    "    #W_H1_H2 -= lr * np.matmul(Capa[-3].T, layer2_delta)\n",
    "    #W_I_H1 -= lr * np.matmul(Capa[-4].T, layer1_delta)\n",
    "    \n",
    "    #W = [W_I_H1, W_H1_H2, W_H2_O]\n",
    "    \n",
    "    layer3_delta = Capa[-1] - labelXor #Error entre predicción y salida real\n",
    "    layer2_delta = np.matmul(layer3_delta, W[-1].T) * relu_deriv(Capa[-2])\n",
    "    layer1_delta = np.matmul(layer2_delta, W[-2].T) * relu_deriv(Capa[-3])\n",
    "\n",
    "    #Actualización de pesos\n",
    "    W[-1] -= lr * np.matmul(Capa[-2].T, layer3_delta)\n",
    "    W[-2] -= lr * np.matmul(Capa[-3].T, layer2_delta)\n",
    "    W[-3] -= lr * np.matmul(Capa[-4].T, layer1_delta)\n",
    "    \n",
    "    print('Iteración ' + str(epoch) + ' - Error: ' + str(error))\n",
    "    #print(error)\n",
    "    #print(lr * np.matmul(Capa[-2].T, layer3_delta))\n",
    "    #Recorre desde la capa de salida hasta la de entrada\n",
    "    #for i in range(-1, -len(Capa)-1, -1):\n",
    "        #print(Capa[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0. -0. -0.]]\n",
      "[[0. 0.]]\n",
      "[[0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 1]]) \n",
    "\n",
    "#Ciclo para calcular los valores de cada capa\n",
    "#Recorre desde la capa de entrada hasta la de salida\n",
    "for i in range(0, len(W)):\n",
    "    z = np.matmul(A, W[i]) #Preactivación \n",
    "    A = relu(z) #Activación \n",
    "    print(A)\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal\n",
    "Las pruebas de arriba servirán para escribir la función final de la red neuronal. Se diseñará una clase con los métodos respectivos para entrenar y predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedNeuronal:\n",
    "    def __init__(self, layer1_size=2):\n",
    "        np.random.seed(1)\n",
    "        self.inicializar(layer1_size)\n",
    "        self.entrenado = False #Indicar si ya están entrenados los pesos\n",
    "    \n",
    "    def inicializar(self, layer1_size):\n",
    "        W_I_H1 = np.random.normal(loc=0, scale=0.1, size=(2, layer1_size)) #Capa oculta de layer1_size neuronas\n",
    "        W_H1_H2 = np.random.normal(loc=0, scale=0.1, size=(layer1_size, 2)) #Capa oculta de 2 neuronas\n",
    "        W_H2_O = np.random.normal(loc=0, scale=0.1, size=(2, 1)) #Pesos hacia la capa de salida\n",
    "        self.W = [W_I_H1, W_H1_H2, W_H2_O]\n",
    "    \n",
    "    def entrenar(self, df, labels, lr=0.1, epochs=50):\n",
    "        #Verificar si ya fue entrenado previamente\n",
    "        if(self.entrenado == True):\n",
    "            self.inicializar(self.W[0].shape[1]) #Resetear los pesos\n",
    "            \n",
    "        #Ciclo de iteraciones \n",
    "        for epoch in range(0, epochs):\n",
    "            # --- Forward propagation ---\n",
    "            A = df #Entrada original\n",
    "            Capa = [] #Almacenamiento de resultados intermedios\n",
    "            Capa.append(A) #Capa 0 = input \n",
    "\n",
    "            #Ciclo para calcular los valores intermedios de cada capa\n",
    "            #Recorre desde la capa de entrada hasta la de salida\n",
    "            for pesos in self.W:\n",
    "                z = np.matmul(A, pesos) #Preactivación \n",
    "                A = relu(z) #Activación \n",
    "                Capa.append(A)\n",
    "\n",
    "            # --- Backward propagation ---\n",
    "            error = (0.5*(Capa[-1] - labels)**2).mean()\n",
    "\n",
    "            #Derivadas parciales\n",
    "            layer3_delta = Capa[-1] - labels #Error entre predicción y salida real\n",
    "            layer2_delta = np.matmul(layer3_delta, self.W[-1].T) * relu_deriv(Capa[-2]) #Propagar error de capa 3 a la 2\n",
    "            layer1_delta = np.matmul(layer2_delta, self.W[-2].T) * relu_deriv(Capa[-3]) #Propagar error de capa 2 a la 1\n",
    "\n",
    "            #Actualización de pesos\n",
    "            self.W[-1] -= lr * np.matmul(Capa[-2].T, layer3_delta) #Actualiza W_H2_O\n",
    "            self.W[-2] -= lr * np.matmul(Capa[-3].T, layer2_delta) #Actualiza W_H1_H2\n",
    "            self.W[-3] -= lr * np.matmul(Capa[-4].T, layer1_delta) #Actualiza W_I_H1\n",
    "            \n",
    "            if(epoch % 10 == 4):\n",
    "                print('Iteración ' + str(epoch) + ' - Error: ' + str(error))\n",
    "        \n",
    "        #Indicar que ya se entrenó la red\n",
    "        #Si se intenta volver a entrenar, se volverán a inicializar los parámetros\n",
    "        self.entrenado = True\n",
    "    \n",
    "    def predecir(self, X): #Recibe una matriz de N filas y 2 columnas\n",
    "        A = X\n",
    "        Capa2 = []\n",
    "        for i in range(0, len(self.W)):\n",
    "            z = np.matmul(A, self.W[i]) #Preactivación \n",
    "            A = relu(z) #Activación \n",
    "            if(i == 1): #Retornar representación de la segunda capa\n",
    "                Capa2 = A\n",
    "        return A, Capa2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos\n",
    "Realizar al menos 5 experimentos, variando learnog rate, epochs y tamaño de la primera capa oculta.\n",
    "\n",
    "**Experimento 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimento1 = RedNeuronal(2) #Primera capa oculta de 2 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 - Error: 0.125\n",
      "Iteración 14 - Error: 0.125\n",
      "Iteración 24 - Error: 0.125\n",
      "Iteración 34 - Error: 0.125\n",
      "Iteración 44 - Error: 0.125\n"
     ]
    }
   ],
   "source": [
    "experimento1.entrenar(tablaXor, labelXor, lr=0.2) \n",
    "#El error baja muy lentamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]]),\n",
       " array([[ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.89709302, -0.        ],\n",
       "        [ 0.        ,  0.        ]]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimento1.predecir(tablaXor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experimento 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimento2 = RedNeuronal(2) #Primera capa oculta de 2 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 - Error: 0.2498066077888068\n",
      "Iteración 14 - Error: 0.24932699223116847\n",
      "Iteración 24 - Error: 0.24669127669301869\n",
      "Iteración 34 - Error: 0.20888564105098814\n",
      "Iteración 44 - Error: 0.12953556110898276\n",
      "Iteración 54 - Error: 0.12500004566689749\n",
      "Iteración 64 - Error: 0.12500000000012612\n",
      "Iteración 74 - Error: 0.125\n"
     ]
    }
   ],
   "source": [
    "experimento2.entrenar(tablaXor, labelXor, lr=0.3, epochs=80) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [1.00000000e+00],\n",
       "        [2.55794741e-11]]),\n",
       " array([[ 0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00],\n",
       "        [ 8.98286054e-01, -0.00000000e+00],\n",
       "        [ 2.29776848e-11, -0.00000000e+00]]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimento2.predecir(tablaXor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experimento 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 - Error: 0.24988105518633186\n",
      "Iteración 14 - Error: 0.2478517626459687\n",
      "Iteración 24 - Error: 0.19122228205405717\n",
      "Iteración 34 - Error: 0.0019975492278509945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.        ],\n",
       "        [0.99459862],\n",
       "        [0.99365462],\n",
       "        [0.        ]]),\n",
       " array([[ 0.        ,  0.        ],\n",
       "        [ 0.694437  , -0.        ],\n",
       "        [ 0.69377789, -0.        ],\n",
       "        [ 0.        ,  0.        ]]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimento3 = RedNeuronal(3) #Primera capa oculta de 3 neuronas\n",
    "experimento3.entrenar(tablaXor, labelXor, lr=0.4, epochs=40) \n",
    "experimento3.predecir(tablaXor)\n",
    "#Los valores muy cercanos a lo verdadero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experimento 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 - Error: 0.24979207323786093\n",
      "Iteración 14 - Error: 0.2449094736398387\n",
      "Iteración 24 - Error: 0.04736098739042249\n",
      "Iteración 34 - Error: 9.222407497209837e-05\n",
      "Iteración 44 - Error: 0.00012943745469205196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.        ],\n",
       "        [0.97593322],\n",
       "        [0.97391486],\n",
       "        [0.        ]]),\n",
       " array([[ 0.        ,  0.        ],\n",
       "        [ 0.69370396, -0.        ],\n",
       "        [ 0.69226929, -0.        ],\n",
       "        [ 0.        ,  0.        ]]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimento4 = RedNeuronal(3) #Primera capa oculta de 3 neuronas\n",
    "experimento4.entrenar(tablaXor, labelXor, lr=0.5, epochs=50) \n",
    "experimento4.predecir(tablaXor)\n",
    "#Los valores muy cercanos a lo verdadero y el error es bastante menor al experimento 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experimento 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 4 - Error: 0.25\n",
      "Iteración 14 - Error: 0.24998313186935833\n",
      "Iteración 24 - Error: 0.24990521745335767\n",
      "Iteración 34 - Error: 0.2485237497347504\n",
      "Iteración 44 - Error: 0.16146103390641736\n",
      "Iteración 54 - Error: 0.07375044362774134\n",
      "Iteración 64 - Error: 0.0014274764901362254\n",
      "Iteración 74 - Error: 0.0006857484851973572\n",
      "Iteración 84 - Error: 0.00035362746450982364\n",
      "Iteración 94 - Error: 0.00018768952367313702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.        ],\n",
       "        [1.02327147],\n",
       "        [1.02218661],\n",
       "        [0.        ]]),\n",
       " array([[ 0.        ,  0.        ],\n",
       "        [ 0.73810653, -0.        ],\n",
       "        [ 0.737324  , -0.        ],\n",
       "        [ 0.        ,  0.        ]]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimento5 = RedNeuronal(4) #Primera capa oculta de 4 neuronas\n",
    "experimento5.entrenar(tablaXor, labelXor, lr=0.5, epochs=100) \n",
    "experimento5.predecir(tablaXor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión \n",
    "En todas las representaciones intermedias de la segunda capa solamente una de las neuronas parece tener relevancia para el resultado final. El segundo array que devuelve la función Predecir nos da dicha representación intermedia y, en los 5 experimentos, la segunda neurona siempre es 0, por lo que podemos afirmar que la red determina que solo una de las neuronas previas a la salida es relevante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
